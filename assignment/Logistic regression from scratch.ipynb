{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eiDWcM_MC3H"
      },
      "source": [
        "# <font color='red'>Implement SGD Classifier with Logloss and L2 regularization Using SGD without using sklearn</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfe2NTQtLq11"
      },
      "source": [
        "**There will be some functions that start with the word \"grader\" ex: grader_weights(), grader_sigmoid(), grader_logloss() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk5DSPCLxqT-"
      },
      "source": [
        "<font color='red'> Importing packages</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42Et8BKIxnsp"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import linear_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpSk3WQBx7TQ"
      },
      "source": [
        "<font color='red'>Creating custom dataset</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsMp0oWzx6dv"
      },
      "source": [
        "# please don't change random_state\n",
        "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
        "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)\n",
        "# make_classification is used to create custom dataset \n",
        "# Please check this link (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) for more details"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8W2fg1cyGdX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7970a81c-5b1d-4927-8aa3-886132036276"
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 15), (50000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x99RWCgpqNHw"
      },
      "source": [
        "<font color='red'>Splitting data into train and test </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Kh4dBfVyJMP"
      },
      "source": [
        "#please don't change random state\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gONY1YiDq7jD"
      },
      "source": [
        "# Standardizing the data.\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(X_train)\n",
        "x_test = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DR_YMBsyOci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3906aa63-3970-4259-9c87-b667fb7f338d"
      },
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((37500, 15), (37500,), (12500, 15), (12500,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW4OHswfqjHR"
      },
      "source": [
        "# <font color='red' size=5>SGD classifier</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HpvTwDHyQQy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cefb32c3-99cf-4559-cff6-369fc58f7f5c"
      },
      "source": [
        "# alpha : float\n",
        "# Constant that multiplies the regularization term. \n",
        "\n",
        "# eta0 : double\n",
        "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
        "\n",
        "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
        "clf\n",
        "# Please check this documentation (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
              "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
              "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
              "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
              "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYaVyQ2lyXcr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d0b6b4a-7e4b-4bbc-9c2c-f357466edeb4"
      },
      "source": [
        "clf.fit(X=X_train, y=y_train) # fitting our model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Epoch 1\n",
            "Norm: 0.77, NNZs: 15, Bias: -0.316653, T: 37500, Avg. loss: 0.455552\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.91, NNZs: 15, Bias: -0.472747, T: 75000, Avg. loss: 0.394686\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.98, NNZs: 15, Bias: -0.580082, T: 112500, Avg. loss: 0.385711\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 15, Bias: -0.658292, T: 150000, Avg. loss: 0.382083\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.04, NNZs: 15, Bias: -0.719528, T: 187500, Avg. loss: 0.380486\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.05, NNZs: 15, Bias: -0.763409, T: 225000, Avg. loss: 0.379578\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.06, NNZs: 15, Bias: -0.795106, T: 262500, Avg. loss: 0.379150\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.06, NNZs: 15, Bias: -0.819925, T: 300000, Avg. loss: 0.378856\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1.07, NNZs: 15, Bias: -0.837805, T: 337500, Avg. loss: 0.378585\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1.08, NNZs: 15, Bias: -0.853138, T: 375000, Avg. loss: 0.378630\n",
            "Total training time: 0.12 seconds.\n",
            "Convergence after 10 epochs took 0.12 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
              "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
              "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
              "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
              "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAfkVI6GyaRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cf7fc9b-1b9d-47bb-fd5c-43f16e1e150c"
      },
      "source": [
        "clf.coef_, clf.coef_.shape, clf.intercept_\n",
        "#clf.coef_ will return the weights\n",
        "#clf.coef_.shape will return the shape of weights\n",
        "#clf.intercept_ will return the intercept term"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.42336692,  0.18547565, -0.14859036,  0.34144407, -0.2081867 ,\n",
              "          0.56016579, -0.45242483, -0.09408813,  0.2092732 ,  0.18084126,\n",
              "          0.19705191,  0.00421916, -0.0796037 ,  0.33852802,  0.02266721]]),\n",
              " (1, 15),\n",
              " array([-0.8531383]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-CcGTKgsMrY"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "## <font color='red' size=5> Implement Logistic Regression with L2 regularization Using SGD: without using sklearn </font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1_8bdzitDlM"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "1.  We will be giving you some functions, please write code in that functions only.\n",
        "\n",
        "2.  After every function, we will be giving you expected output, please make sure that you get that output. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU2Y3-FQuJ3z"
      },
      "source": [
        "\n",
        "<br>\n",
        "\n",
        "* Initialize the weight_vector and intercept term to zeros (Write your code in <font color='blue'>def initialize_weights()</font>)\n",
        "\n",
        "* Create a loss function (Write your code in <font color='blue'>def logloss()</font>) \n",
        "\n",
        " $log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$\n",
        "- for each epoch:\n",
        "\n",
        "    - for each batch of data points in train: (keep batch size=1)\n",
        "\n",
        "        - calculate the gradient of loss function w.r.t each weight in weight vector (write your code in <font color='blue'>def gradient_dw()</font>)\n",
        "\n",
        "        $dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)})$ <br>\n",
        "\n",
        "        - Calculate the gradient of the intercept (write your code in <font color='blue'> def gradient_db()</font>) <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
        "\n",
        "           $ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t}))$\n",
        "\n",
        "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
        "        $w^{(t+1)}← w^{(t)}+α(dw^{(t)}) $<br>\n",
        "\n",
        "        $b^{(t+1)}←b^{(t)}+α(db^{(t)}) $\n",
        "    - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
        "    - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
        "        you can stop the training\n",
        "    - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR_HgjgS_wKu"
      },
      "source": [
        "<font color='blue'>Initialize weights </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GecwYV9fsKZ9"
      },
      "source": [
        "def initialize_weights(dim):\n",
        "    ''' In this function, we will initialize our weights and bias'''\n",
        "    #initialize the weights to zeros array of (1,dim) dimensions\n",
        "    #you use zeros_like function to initialize zero, check this link https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
        "    #initialize bias to zero\n",
        "    w =np.zeros_like(dim)\n",
        "    b = 0\n",
        "    return w,b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7I6uWBRsKc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccfae7b5-9b37-4db6-d1f5-ff2a3c94035f"
      },
      "source": [
        "dim=X_train[0] \n",
        "w,b = initialize_weights(dim)\n",
        "print('w =',(w))\n",
        "print('b =',str(b))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "b = 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MI5SAjP9ofN"
      },
      "source": [
        "<font color='cyan'>Grader function - 1 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv1llH429wG5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74797525-1ae3-4f68-df24-c4579176a516"
      },
      "source": [
        "dim=X_train[0] \n",
        "w,b = initialize_weights(dim)\n",
        "def grader_weights(w,b):\n",
        "  assert((len(w)==len(dim)) and b==0 and np.sum(w)==0.0)\n",
        "  return True\n",
        "grader_weights(w,b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QN83oMWy_5rv"
      },
      "source": [
        "<font color='blue'>Compute sigmoid </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPv4NJuxABgs"
      },
      "source": [
        "$sigmoid(z)= 1/(1+exp(-z))$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAfmQF47_Sd6"
      },
      "source": [
        "\n",
        "def sigmoid(z):\n",
        "    ''' In this function, we will return sigmoid of z'''\n",
        "    # compute sigmoid(z) and return\n",
        "    s = np.exp(-z)\n",
        "    sig = 1/(1+s)\n",
        "\n",
        "    return sig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YrGDwg3Ae4m"
      },
      "source": [
        "<font color='cyan'>Grader function - 2</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_JASp_NAfK_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f475b86e-2e2e-4a2a-b644-8875dca4f1e7"
      },
      "source": [
        "def grader_sigmoid(z):\n",
        "  val=sigmoid(z)\n",
        "  assert(val==0.8807970779778823)\n",
        "  return True\n",
        "grader_sigmoid(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS7JXbcrBOFF"
      },
      "source": [
        "<font color='blue'> Compute loss </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfEiS22zBVYy"
      },
      "source": [
        "$log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaFDgsp3sKi6"
      },
      "source": [
        "import math\n",
        "def logloss(y_true,y_pred):\n",
        "    '''In this function, we will compute log loss '''\n",
        "\n",
        "    lst1 = y_true\n",
        "    lst2 = y_pred\n",
        "    loss = 0\n",
        "    for i in range(len(lst1)):\n",
        "        loss = loss + (lst1[i] * math.log10(lst2[i])) + ((1-lst1[i]) * math.log10(1-lst2[i]))\n",
        "\n",
        "    loss = (-1/len(lst1))* (loss)\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs1BTXVSClBt"
      },
      "source": [
        "<font color='cyan'>Grader function - 3 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzttjvBFCuQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce5b8ef3-8354-45d4-a44a-58b228fa2fc4"
      },
      "source": [
        "def grader_logloss(true,pred):\n",
        "  loss=logloss(true,pred)\n",
        "  assert(loss==0.07644900402910389)\n",
        "  return True\n",
        "true=[1,1,0,1,0]\n",
        "pred=[0.9,0.8,0.1,0.8,0.2]\n",
        "grader_logloss(true,pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQabIadLCBAB"
      },
      "source": [
        "<font color='blue'>Compute gradient w.r.to  'w' </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTMxiYKaCQgd"
      },
      "source": [
        "$dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)}$ <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMVikyuFsKo5"
      },
      "source": [
        "def gradient_dw(x,y,w,b,alpha,N):\n",
        "    '''In this function, we will compute the gardient w.r.to w '''\n",
        "    dw = []\n",
        "    dw =x*(y-sigmoid(np.dot(w,x)+b)) - ((alpha*w)/N)\n",
        "    return dw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUFLNqL_GER9"
      },
      "source": [
        "<font color='cyan'>Grader function - 4 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI3xD8ctGEnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbba3671-ca92-4b47-cdb9-9a47933f564d"
      },
      "source": [
        "def grader_dw(x,y,w,b,alpha,N):\n",
        "  grad_dw=gradient_dw(x,y,w,b,alpha,N)\n",
        "  assert(np.sum(grad_dw)==2.613689585)\n",
        "  return True\n",
        "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
        "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
        "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
        "grad_y=0\n",
        "grad_w,grad_b=initialize_weights(grad_x)\n",
        "alpha=0.0001\n",
        "N=len(X_train)\n",
        "grader_dw(grad_x,grad_y,grad_w,grad_b,alpha,N)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE8g84_GI62n"
      },
      "source": [
        "<font color='blue'>Compute gradient w.r.to 'b' </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHvTYZzZJJ_N"
      },
      "source": [
        "$ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t})$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nUf2ft4EZp8"
      },
      "source": [
        " def gradient_db(x,y,w,b):\n",
        "    '''In this function, we will compute gradient w.r.to b '''\n",
        "\n",
        "    db =(y-sigmoid(np.dot(w,x)+b))\n",
        "    return db"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbcBzufVG6qk"
      },
      "source": [
        "<font color='cyan'>Grader function - 5 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfFDKmscG5qZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "485d0cba-9cfd-4475-eb07-6413eeccfb46"
      },
      "source": [
        "def grader_db(x,y,w,b):\n",
        "  grad_db=gradient_db(x,y,w,b)\n",
        "  assert(grad_db==-0.5)\n",
        "  return True\n",
        "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
        "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
        "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
        "grad_y=0\n",
        "grad_w,grad_b=initialize_weights(grad_x)\n",
        "alpha=0.0001\n",
        "N=len(X_train)\n",
        "grader_db(grad_x,grad_y,grad_w,grad_b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtwRSy6TyWtq"
      },
      "source": [
        "def pred_score(w,b, X):\r\n",
        "    N = len(X)\r\n",
        "    predict = []\r\n",
        "    for i in range(N):\r\n",
        "        z=np.dot(w,X[i])+b\r\n",
        "        predict.append(sigmoid(z))\r\n",
        "    return predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCK0jY_EOvyU"
      },
      "source": [
        "<font color='blue'> Implementing logistic regression</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmAdc5ejEZ25"
      },
      "source": [
        "def train(X_train,y_train,X_test,y_test,epochs,alpha,eta0):\n",
        "    ''' In this function, we will implement logistic regression'''\n",
        "    #Here eta0 is learning rate\n",
        "    #implement the code as follows\n",
        "    # initalize the weights (call the initialize_weights(X_train[0]) function)\n",
        "    dim=X_train[0]\n",
        "    w,b = initialize_weights(dim)  \n",
        "    train_loss = [] \n",
        "    test_loss=[]\n",
        "    epoch = 0\n",
        "    epoch_lst = []\n",
        "    # for every epoch\n",
        "    for i in range(epochs):\n",
        "        # for every data point(X_train,y_train)\n",
        "        for j in range(len(X_train)):\n",
        "           #compute gradient w.r.to w (call the gradient_dw() function)\n",
        "           grad_dw =  gradient_dw(X_train[j],y_train[j],w,b,alpha,len(X_train))\n",
        "           #compute gradient w.r.to b (call the gradient_db() function)\n",
        "           grad_db = gradient_db(X_train[j],y_train[j],w,b)\n",
        "           #update w, b\n",
        "           w = w + alpha * (grad_dw)\n",
        "           b = b + alpha * (grad_db)\n",
        "        # predict the output of x_train[for all data points in X_train] using w,b\n",
        "        predict_train = pred_score(w,b,X_train)\n",
        "        #compute the loss between predicted and actual values (call the loss function)\n",
        "        a = logloss(y_train,predict_train)\n",
        "        # store all the train loss values in a list\n",
        "        train_loss.append(a)\n",
        "        # predict the output of x_test[for all data points in X_test] using w,b\n",
        "        predict_test = pred_score(w,b,X_test)\n",
        "        #compute the loss between predicted and actual values (call the loss function)\n",
        "        a_test = logloss(y_test,predict_test)\n",
        "        # store all the test loss values in a list\n",
        "        test_loss.append(a_test)\n",
        "        epoch_lst.append(i)\n",
        "        # you can also compare previous loss and current loss, if loss is not updating then stop the process and return w,b\n",
        "        if((test_loss[i-1]-a_test)<0.0001 and (i>0)):\n",
        "            break\n",
        "    \n",
        "    return w,b,train_loss,test_loss,epoch_lst"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUquz7LFEZ6E"
      },
      "source": [
        "alpha=0.0001\n",
        "eta0=0.0001\n",
        "N=len(X_train)\n",
        "epochs=50\n",
        "epoch=[]\n",
        "train_loss=[]\n",
        "test_loss=[]\n",
        "w,b,train_loss,test_loss,epoch=train(X_train,y_train,X_test,y_test,epochs,alpha,eta0)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4Zf_wPARlwY"
      },
      "source": [
        "<font color='red'>Goal of assignment</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3eF_VSPSH2z"
      },
      "source": [
        "Compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx8Rs9rfEZ1R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab723f41-5444-4e2b-833d-b8f5d5992d6f"
      },
      "source": [
        "# these are the results we got after we implemented sgd and found the optimal weights and intercept\n",
        "w-clf.coef_, b-clf.intercept_"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 5.32478821e-03,  3.85354323e-03,  4.94640750e-03,\n",
              "         -3.42760674e-03,  3.48468755e-03,  1.22744016e-03,\n",
              "          6.78036985e-03,  1.02015463e-03,  5.70949454e-03,\n",
              "         -1.42555091e-02, -4.56856697e-03,  1.95513439e-04,\n",
              "          4.46342480e-03,  6.33482932e-05, -1.10408984e-03]]),\n",
              " array([0.0344035]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "230YbSgNSUrQ"
      },
      "source": [
        "<font color='blue'>Plot epoch number vs train , test loss </font>\n",
        "\n",
        "* epoch number on X-axis\n",
        "* loss on Y-axis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1O6GrRt7UeCJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "69cb3f1b-3892-4e8c-8a9d-d23277eaf94b"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "plt.plot(train_loss, label = 'Train_loss')\r\n",
        "plt.plot(test_loss, label = 'Test_loss')\r\n",
        "plt.scatter(epoch, train_loss)\r\n",
        "plt.scatter(epoch, test_loss)\r\n",
        "plt.xlabel('Iterations - epoch')\r\n",
        "plt.ylabel('log_loss')\r\n",
        "plt.grid(True)\r\n",
        "plt.legend\r\n",
        "plt.show()\r\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUN8puFoEZtU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0215356d-29b4-4b2d-883e-187a231da75e"
      },
      "source": [
        "def pred(w,b, X):\n",
        "    N = len(X)\n",
        "    predict = []\n",
        "    for i in range(N):\n",
        "        z=np.dot(w,X[i])+b\n",
        "        if sigmoid(z) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
        "            predict.append(1)\n",
        "        else:\n",
        "            predict.append(0)\n",
        "    return np.array(predict)\n",
        "print(1-np.sum(y_train - pred(w,b,X_train))/len(X_train))\n",
        "print(1-np.sum(y_test  - pred(w,b,X_test))/len(X_test))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9577333333333333\n",
            "0.95568\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}